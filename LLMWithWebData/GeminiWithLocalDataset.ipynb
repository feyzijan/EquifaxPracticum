{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- Loop through the firms in the bing web search and website scraping databases, and generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import time\n",
    "import sqlite3\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from gemini_prompts import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Configure Model\n",
    "- You need a .env file with GEMINI_API_KEY defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY_PAID\"))\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  # model_name=\"gemini-1.5-pro-002\",\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  generation_config=generation_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"Hello there, what is your name \")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define functions to form prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update prompts in the gemini_prompts.py file \n",
    "context =  context_local_dataset_v1 + context_single_field_v1\n",
    "answer_format = answer_format_v1\n",
    "field_to_query = field_to_query_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_prompt(query, local_data):\n",
    "    prompt = f\"\"\"\n",
    "\n",
    "    {context}\n",
    "    {query}\n",
    "    {answer_format}\n",
    "\n",
    "    Here are the results of my search for this firm.\n",
    "    {local_data}\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Connect to the source and target databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"firm_database_llm.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Drop the table if you're starting from scratch\n",
    "# cursor.execute('''\n",
    "# DROP TABLE IF EXISTS firm_properties\n",
    "#                ''')\n",
    "\n",
    "table_name = \"firm_properties_gemini_without_grounding_local_dataset_v1\"\n",
    "# You can create different tables for different prompt types, gemini model etc, if you rename the table\n",
    "cursor.execute(f'''\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "               id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "               Firm_Name TEXT NOT NULL,\n",
    "               Registered_Address TEXT,\n",
    "               CEO TEXT,\n",
    "               Establishment_Year INT,\n",
    "               Number_Of_Employees INT,\n",
    "               Revenue_Size INT,\n",
    "               Website TEXT,\n",
    "               NAICS_Code INT,\n",
    "               SIC_Code INT,\n",
    "               Status TEXT,\n",
    "               Dissolvement_Year INT,\n",
    "               Company_Type TEXT,\n",
    "               Previous_Names TEXT, \n",
    "               Alternative_Names TEXT, \n",
    "               Key_Executive_Personnel TEXT\n",
    "               )\n",
    "               ''')\n",
    "\n",
    "\n",
    "web_search_table_name = \"firms_web_search_results\"\n",
    "webscraping_table_name = \"firms_web_search_website_scrapings\"\n",
    "conn_web_results = sqlite3.connect(\"firms_web_search_results.db\")\n",
    "conn_websites = sqlite3.connect(\"firms_web_search_website_scrapings.db\")\n",
    "cursor_websearch = conn_web_results.cursor()\n",
    "cursor_websites = conn_websites.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check existing tables in the database\n",
    "existing_tables = cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "print(existing_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_to_drop = \"firm_properties_gemini_without_grounding_local_dataset_v1\"\n",
    "# cursor.execute(f\"DROP TABLE IF EXISTS {table_to_drop} \")\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data_length_allowed = 1000000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Override with sample firms for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"firms_sample.csv\") \n",
    "# change this to all firms in the bing search database for actual run\n",
    "# cursor_websearch.execute(f\"SELECT * FROM {web_search_table_name}\").fetchall()\n",
    "for i,row in df.iterrows():\n",
    "    row = row.to_dict()\n",
    "    print(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Main Loop\n",
    "- Parallelize with an executor for each field, update all fields of a single row at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_field(field, firm_id, firm_name, updated_query, max_data_length_allowed):\n",
    "    # Open new connections for each thread (SQLite connections are not thread-safe)\n",
    "    conn_websearch_thread = sqlite3.connect('firms_web_search_results.db')\n",
    "    cursor_websearch_thread = conn_websearch_thread.cursor()\n",
    "\n",
    "    conn_websites_thread = sqlite3.connect('firms_web_search_website_scrapings.db')\n",
    "    cursor_websites_thread = conn_websites_thread.cursor()\n",
    "\n",
    "    # Get the web search results\n",
    "    cursor_websearch_thread.execute(f\"SELECT {field} FROM firms_web_search_results WHERE id = ? AND Firm_Name = ?\", (firm_id, firm_name,))\n",
    "    web_search_result = cursor_websearch_thread.fetchone()\n",
    "    if web_search_result is not None and web_search_result[0]:\n",
    "        web_search_result = json.loads(web_search_result[0])\n",
    "    else:\n",
    "        web_search_result = \"No web search data available\"\n",
    "\n",
    "    # Get the website scraping results\n",
    "    cursor_websites_thread.execute(f\"SELECT {field} FROM firms_web_search_website_scrapings WHERE id = ? AND Firm_Name = ?\", (firm_id, firm_name,))\n",
    "    website_scraping_result = cursor_websites_thread.fetchone()\n",
    "    if website_scraping_result is not None and website_scraping_result[0]:\n",
    "        website_scraping_result = json.loads(website_scraping_result[0])\n",
    "        # Check if scraped contents are too long\n",
    "        if len(json.dumps(website_scraping_result)) > max_data_length_allowed:\n",
    "            print(f\"Scraped contents for {firm_name} - {field} is too long. Skipping.\")\n",
    "            website_scraping_result = \"No website scraping data available\"\n",
    "    else:\n",
    "        website_scraping_result = \"No website scraping data available\"\n",
    "\n",
    "    data_to_pass_llm = {\n",
    "        f\"Results of searching the web for {firm_name}\": web_search_result,\n",
    "        f\"Scraped contents of top websites for {firm_name}\": website_scraping_result\n",
    "    }\n",
    "\n",
    "    # Generate the prompt\n",
    "    prompt = form_prompt(updated_query, data_to_pass_llm)\n",
    "\n",
    "    # Call the LLM to get the response\n",
    "    response = model.generate_content(prompt).text\n",
    "\n",
    "    print(f\"Response for the firm named: {firm_name}, with id  {firm_id}, for the field {field} is {response} \")\n",
    "\n",
    "    # Close the thread-specific connections\n",
    "    conn_websearch_thread.close()\n",
    "    conn_websites_thread.close()\n",
    "\n",
    "    return field, response\n",
    "\n",
    "\n",
    "# Main processing loop\n",
    "for i,row in df.iterrows():\n",
    "    row = row.to_dict()\n",
    "    firm_id = row['id']\n",
    "    firm_name = row['name']\n",
    "    print(\"\\n ---- Debug now for \", firm_name, \"id\", firm_id)\n",
    "\n",
    "    # Check if firm already exists, insert row if it doesn't\n",
    "    cursor.execute(f\"SELECT id FROM {table_name} WHERE id = ? AND Firm_Name = ?\", (firm_id, firm_name,))\n",
    "    firm_row = cursor.fetchone()\n",
    "    if firm_row is None:\n",
    "        print(\"Inserting new firm: \", firm_name)\n",
    "        cursor.execute(f\"INSERT INTO {table_name} (id, Firm_Name) VALUES (?, ?)\", (firm_id, firm_name))\n",
    "        conn.commit()\n",
    "    else:\n",
    "        # Get the existing firm's id\n",
    "        print(\"Found row for firm: \", firm_name, firm_id)\n",
    "\n",
    "    # Update queries with firm name\n",
    "    updated_queries = {key: value.format(firm_name=firm_name) for key, value in field_to_query.items()}\n",
    "\n",
    "    # List to hold fields that need processing\n",
    "    fields_to_process = []\n",
    "\n",
    "    for field in fields:\n",
    "        # Check if the field value in the prediction database is NULL\n",
    "        cursor.execute(f\"SELECT {field} FROM {table_name} WHERE id = ? AND Firm_Name = ? AND {field} IS NOT NULL\", (firm_id, firm_name,))\n",
    "        if cursor.fetchone() is not None:\n",
    "            # print(f\"Field '{field}' already has data for firm '{firm_name}', skipping.\")\n",
    "            continue\n",
    "        else:\n",
    "            fields_to_process.append(field)\n",
    "\n",
    "    # If there are no fields to process, continue to the next firm\n",
    "    if not fields_to_process:\n",
    "        continue\n",
    "\n",
    "    # Use ThreadPoolExecutor to process fields in parallel else its kinda slow\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor(max_workers=14) as executor:\n",
    "        # Create a future for each field\n",
    "        futures = {\n",
    "            executor.submit(process_field, field, firm_id, firm_name, updated_queries[field], max_data_length_allowed): field\n",
    "            for field in fields_to_process\n",
    "        }\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            field = futures[future]\n",
    "            try:\n",
    "                field, response = future.result()\n",
    "                if response is not None:\n",
    "                    results[field] = response\n",
    "            except Exception as e:\n",
    "                print(f\"Error in future for field {field}: {e}\")\n",
    "    \n",
    "    time.sleep(1) # avoid hitting the gemini quota per minute\n",
    "\n",
    "    # Updat database sequentially\n",
    "    for field, response in results.items():\n",
    "        # print(f\"Updating database for {firm_name} - {field}\")\n",
    "        cursor.execute(f\"UPDATE {table_name} SET {field} = ? WHERE Firm_Name = ? AND id = ?\", (response, firm_name, firm_id))\n",
    "        conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df.name.tolist()\n",
    "data = cursor.execute(\"SELECT * FROM {} WHERE Firm_Name IN ({})\".format(table_name, \",\".join([\"?\"] * len(df))\n",
    "), names).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equifax_practicum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
