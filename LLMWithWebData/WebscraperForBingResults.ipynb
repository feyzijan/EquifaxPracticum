{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This code uses selenium and requests to scrape the contents of the top 5 websites found in the bing web search results for each Firm_Name and Field. It reads in data from \"firms_web_search_results.db\" and stores website scraping results in \"firms_web_search_website_scrapings.db\".\n",
    "- It will skip over fields that are already populated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import sqlite3\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.exceptions import Timeout, RequestException\n",
    "\n",
    "from gemini_prompts import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define Class for webscraping\n",
    "- Uses requests and selenium to scrape a website, and returns the text with the longest length\n",
    "- *IMPORTANT*: Update CHROMEDRIVER_PATH with the path to your chrome driver installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_web_result = \"No website scrapings found\"\n",
    "class SeleniumExtractionError(Exception):\n",
    "    \"\"\"Custom exception for Selenium extraction errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "CHROMEDRIVER_PATH = '/opt/homebrew/bin/chromedriver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraper():\n",
    "    def __init__(self) -> None:\n",
    "        # Set up Chrome driver with webdriver manager\n",
    "        self.options = webdriver.ChromeOptions()\n",
    "        self.options.add_argument('--headless')  # Run headless for no browser window\n",
    "        self.options.add_argument('--disable-gpu')  # Disable GPU acceleration\n",
    "        self.options.add_argument('--no-sandbox')  # Required for some Linux environments\n",
    "        self.options.add_argument('--disable-extensions')\n",
    "        self.options.add_argument('--disable-plugins')\n",
    "        self.options.add_argument('--disable-images')  # Prevent loading images to save bandwidth\n",
    "        self.options.add_argument('--disable-browser-side-navigation')\n",
    "        self.options.add_argument('--mute-audio') \n",
    "        self.options.page_load_strategy = 'eager'  \n",
    "\n",
    "        # Paremeters for requests\n",
    "        self.requests_headers =  {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        }\n",
    "        self.requests_timeout = 4\n",
    "\n",
    "        self.n_webpages_to_scrape = 5\n",
    "        self.webpages = {}\n",
    "        self.service = Service(executable_path=CHROMEDRIVER_PATH)\n",
    "\n",
    "\n",
    "    def get_top_webpages(self,web_search_results: dict) -> dict:\n",
    "        '''\n",
    "        Get the top n webpages' names and urls from a given Bing search result\n",
    "        Returns dict with 'site_name': 'url' pairs\n",
    "        '''\n",
    "        self.webpages = {}\n",
    "        print(\"Getting urls of top webpages\")\n",
    "    \n",
    "        # get dict of site names and urls\n",
    "        if 'webPages' not in web_search_results.keys():\n",
    "            print(\"No webpages found\")\n",
    "            return self.webpages\n",
    "        else:\n",
    "            for result in web_search_results['webPages']['value']:\n",
    "                # print(\"Result is \", result)\n",
    "                # print(result[\"siteName\"])\n",
    "                if \"siteName\" in result.keys():\n",
    "                    self.webpages[result[\"siteName\"]] = result[\"url\"]\n",
    "                elif \"name\" in result.keys():\n",
    "                    self.webpages[result[\"name\"]] = result[\"url\"]\n",
    "                else:\n",
    "                    pass\n",
    "                if len(self.webpages) >= self.n_webpages_to_scrape:\n",
    "                    break\n",
    "                \n",
    "            # print(\"debug: length of webpages is \", len(self.webpages))\n",
    "            return self.webpages\n",
    "        \n",
    "    def extract_text_with_selenium(self,url):\n",
    "        '''\n",
    "        Extract contents of given url with Selenium with max 5s timeout\n",
    "        Returns text if successful, None otherwise\n",
    "        '''\n",
    "        self.driver = webdriver.Chrome(service=self.service, options=self.options)\n",
    "        self.driver.set_page_load_timeout(4)\n",
    "        try:\n",
    "            # Open the URL in the browser\n",
    "            # print(\"Selenium DEBUG: getting url\")\n",
    "            self.driver.get(url) # KEEPS GETTING STUCK HERE!!!!\n",
    "            time.sleep(0.1) # this counteracts some automatic blocking\n",
    "\n",
    "            # Wait for the page body to be present (max 5 seconds)\n",
    "            WebDriverWait(self.driver, 5).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "            # print(\"Selenium DEBUG: found body\")\n",
    "            # Get page source and parse it after it has fully loaded\n",
    "            page_source = self.driver.page_source\n",
    "            # print(\"Selenium DEBUG: found page source\")\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            text = soup.get_text(separator='\\n')\n",
    "\n",
    "            self.safe_quit_selenium()\n",
    "            # self.safe_quit_selenium()\n",
    "            return text\n",
    "        \n",
    "        except TimeoutException:\n",
    "            error_message = \"Page load exceeded time limit of 5 seconds\"\n",
    "            print(f\"An error occurred with Selenium:: {error_message}\")\n",
    "            # self.safe_quit_selenium()\n",
    "            return \"Page contents not loaded in time\"\n",
    "\n",
    "        except Exception as e:\n",
    "            error_message = str(e)\n",
    "            print(f\"An error occurred with Selenium: {error_message}\")\n",
    "            self.safe_quit_selenium()\n",
    "            if \"disconnected: not connected to DevTools\" in error_message:\n",
    "                print(f\"Error occurred: {error_message}\")\n",
    "                raise SeleniumExtractionError(f\"DevTools disconnection error for URL: {url}\")\n",
    "            else:\n",
    "                raise SeleniumExtractionError(f\"An unexpected error occurred while extracting: {error_message}\")\n",
    "    \n",
    "    def safe_quit_selenium(self):\n",
    "        try:\n",
    "            self.driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error during driver quit: {e}\")\n",
    "            \n",
    "        \n",
    "    def extract_text_with_requests(self,url):\n",
    "        ''' Extract the url with requests and return the text if successfull, None if not'''\n",
    "        try:\n",
    "            # Fetch the content from the URL with headers\n",
    "            response = requests.get(url, headers=self.requests_headers, timeout=self.requests_timeout)\n",
    "            response.raise_for_status()  # Check if the request was successful\n",
    "            # Parse text\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            text = soup.get_text(separator='\\n')  # Using '\\n' to preserve some structure\n",
    "            return text\n",
    "\n",
    "        except Timeout:\n",
    "            print(f\"Request timed out after 5 seconds for URL: {url}\")\n",
    "            return None\n",
    "        except RequestException as e:\n",
    "            print(f\"Requests Error fetching the URL {url}: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Requests Unexpected error occurred while processing {url}: {e}\")\n",
    "            return None\n",
    "        \n",
    "    def scrape_webpage(self, url: str) -> str:\n",
    "        ''' Scrape the given url using selenium and requests, return the longer text'''\n",
    "\n",
    "        # print(\"Extracting webpage with selenium\")\n",
    "        # print(\"---Debug: extracting webpage with url\", url)\n",
    "        text_selenium = self.extract_text_with_selenium(url)\n",
    "        text_requests = self.extract_text_with_requests(url)\n",
    "\n",
    "        texts = [text for text in [text_selenium, text_requests] if text]\n",
    "        if not texts:\n",
    "            return no_web_result\n",
    "\n",
    "        # Return the text with more content\n",
    "        longest_text = max(texts, key=len)\n",
    "        return self.clean_text(longest_text)\n",
    "            \n",
    "    def clean_text(self,text):\n",
    "        ''' Cleans result text '''\n",
    "        if text is None:\n",
    "            return None\n",
    "        # replace multiple newlines with a single one\n",
    "        text = re.sub(r'\\n+', '\\n', text)\n",
    "        # remove leading/trailing whitespaces\n",
    "        text = '\\n'.join(line.strip() for line in text.splitlines())\n",
    "        # Remove extra spaces between words\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text\n",
    "    \n",
    "# Use this to return results for parallel processing\n",
    "def scrape_website(scraper_instance, website_name, website_url):\n",
    "    print(f\"Getting Contents of the website of {website_name} with url {website_url}\")\n",
    "    return website_name, scraper_instance.scrape_webpage(website_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Connect to the source sqlite table that stores web search results, and the target table to store website scrapings\n",
    "- Note: Download the latest firms_web_search_results.db from Google drive (In the datasets folder), and update there when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_websearch = sqlite3.connect(\"firms_web_search_results.db\")\n",
    "conn_websites = sqlite3.connect(\"firms_web_search_website_scrapings.db\")\n",
    "cursor_websearch = conn_websearch.cursor()\n",
    "cursor_websites = conn_websites.cursor()\n",
    "\n",
    "cursor_websites.execute('''\n",
    "CREATE TABLE IF NOT EXISTS firms_web_search_website_scrapings (\n",
    "               id INTEGER PRIMARY KEY,\n",
    "               Firm_Name TEXT NOT NULL,\n",
    "               Registered_Address TEXT,\n",
    "               CEO TEXT,\n",
    "               Establishment_Year TEXT,\n",
    "               Number_Of_Employees TEXT,\n",
    "               Revenue_Size TEXT,\n",
    "               Website TEXT,\n",
    "               NAICS_Code TEXT,\n",
    "               SIC_Code TEXT,\n",
    "               Status TEXT,\n",
    "               Dissolvement_Year TEXT,\n",
    "               Company_Type TEXT,\n",
    "               Previous_Names TEXT,\n",
    "               Alternative_Names TEXT,\n",
    "               Key_Executive_Personnel TEXT\n",
    "               )\n",
    "               ''')\n",
    "\n",
    "conn_websites.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Execute Main Loop to construct the database\n",
    "- Skip over existing entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize 5 webscraper class instances for parallel processing\n",
    "scrapers = [WebScraper() for _ in range(5)]\n",
    "site_scraper = scrapers[0]\n",
    "\n",
    "# Get all firms from the web search results database\n",
    "cursor_websearch.execute(''' SELECT id, Firm_Name FROM firms_web_search_results ''')\n",
    "firm_web_search_results = cursor_websearch.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Override with sample firms for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 2945, 'name': 'Paces'}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"firms_sample.csv\")\n",
    "for i,row in df.iterrows():\n",
    "    row = row.to_dict()\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Debug: Now on firm:  Paces  ----- 2945\n",
      "Inserting new firm:,  Paces\n",
      "Debug field is  Registered_Address  for firm  Paces  and id  2945\n",
      "Getting urls of top webpages\n",
      "Getting Contents of the website of PACES OFFICES – Palestine Association for Children's Encouragement of ... with url https://www.pacescharity.org/regional-office/\n",
      "Getting Contents of the website of Live Active with url https://www.liveactive.co.uk/Sports-Development/paces-accredited-clubs\n",
      "Getting Contents of the website of OpenCorporates with url https://opencorporates.com/companies/us_ga/09069077\n",
      "Getting Contents of the website of The Official Web Site for The State of New Jersey with url https://www.nj.gov/njyrs/education/paces/\n",
      "Getting Contents of the website of SGPBusiness.com with url https://www.sgpbusiness.com/company/Paces-Capital-Management-Pte-Ltd\n",
      "Requests Error fetching the URL https://www.sgpbusiness.com/company/Paces-Capital-Management-Pte-Ltd: 403 Client Error: Forbidden for url: https://www.sgpbusiness.com/company/Paces-Capital-Management-Pte-Ltd\n",
      "****Successfully updated Registered_Address for Paces), counter at 1 ***\n",
      "Debug field is  CEO  for firm  Paces  and id  2945\n",
      "Getting urls of top webpages\n",
      "Getting Contents of the website of Paces Raises $11 Million to Accelerate Clean Energy Development with url https://www.paces.com/news/paces-raises-11-million-to-accelerate-clean-energy-development\n",
      "Getting Contents of the website of About - James McWalter with url https://www.jamesmcwalter.com/about\n",
      "Getting Contents of the website of PACEsConnection with url https://www.pacesconnection.com/blog/ingrid-cockhren-named-ceo-of-paces-connection\n",
      "Getting Contents of the website of About - paces.com with url https://www.paces.com/about\n",
      "Getting Contents of the website of Y Combinator with url https://www.ycombinator.com/companies/paces\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "****Successfully updated CEO for Paces), counter at 2 ***\n",
      "Debug field is  Establishment_Year  for firm  Paces  and id  2945\n",
      "Getting urls of top webpages\n",
      "Getting Contents of the website of Wikipedia with url https://en.wikipedia.org/wiki/Category:Populated_places_by_year_of_establishment\n",
      "Getting Contents of the website of Our History - Paces with url https://www.pacescenter.org/our-history\n",
      "Getting Contents of the website of The Historical Marker Database with url https://www.hmdb.org/m.asp?m=10855\n",
      "Getting Contents of the website of Georgia Historical Society with url https://www.georgiahistory.com/ghmi_marker_updated/old-paces-ferry-road/\n",
      "Getting Contents of the website of Category : Populated places by year of establishment - Wikimedia with url https://commons.wikimedia.org/wiki/Category:Populated_places_by_year_of_establishment\n",
      "Error scraping Wikipedia: Message: Service /opt/homebrew/bin/chromedriver unexpectedly exited. Status code was: 1\n",
      "\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "****Successfully updated Establishment_Year for Paces), counter at 3 ***\n",
      "Debug field is  Number_Of_Employees  for firm  Paces  and id  2945\n",
      "Getting urls of top webpages\n",
      "Getting Contents of the website of A Look Back and the Road Ahead for 2025 - paces.com with url https://www.paces.com/post/a-look-back-and-the-road-ahead-for-2025\n",
      "Getting Contents of the website of Datanyze with url https://www.datanyze.com/companies/paces/344762661\n",
      "Getting Contents of the website of Craft with url https://craft.co/paces\n",
      "Getting Contents of the website of ZoomInfo with url https://www.zoominfo.com/c/paces-inc/410154389\n",
      "Getting Contents of the website of PitchBook with url https://pitchbook.com/profiles/company/491718-52\n",
      "Requests Error fetching the URL https://craft.co/paces: 403 Client Error: Forbidden for url: https://craft.co/paces\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "Requests Error fetching the URL https://pitchbook.com/profiles/company/491718-52: 403 Client Error: Forbidden for url: https://pitchbook.com/profiles/company/491718-52\n",
      "Requests Error fetching the URL https://www.zoominfo.com/c/paces-inc/410154389: 403 Client Error: Forbidden for url: https://www.zoominfo.com/c/paces-inc/410154389\n",
      "Requests Error fetching the URL https://www.datanyze.com/companies/paces/344762661: 403 Client Error: Forbidden for url: https://www.datanyze.com/companies/paces/344762661\n",
      "****Successfully updated Number_Of_Employees for Paces), counter at 4 ***\n",
      "Debug field is  Revenue_Size  for firm  Paces  and id  2945\n",
      "Getting urls of top webpages\n",
      "Getting Contents of the website of PitchBook with url https://pitchbook.com/profiles/company/491718-52\n",
      "Getting Contents of the website of LATKA with url https://getlatka.com/companies/paces.com/funding\n",
      "Getting Contents of the website of Tracxn with url https://tracxn.com/d/companies/paces/__8EXjwSHllCfw6owjGHVpf3XD75wdonZG9IP5AiIKVd4\n",
      "Getting Contents of the website of A Look Back and the Road Ahead for 2025 - paces.com with url https://www.paces.com/post/a-look-back-and-the-road-ahead-for-2025\n",
      "Getting Contents of the website of CB Insights with url https://www.cbinsights.com/company/paces\n",
      "Requests Error fetching the URL https://pitchbook.com/profiles/company/491718-52: 403 Client Error: Forbidden for url: https://pitchbook.com/profiles/company/491718-52\n",
      "Requests Error fetching the URL https://getlatka.com/companies/paces.com/funding: 403 Client Error: Forbidden for url: https://getlatka.com/companies/paces.com/funding\n",
      "****Successfully updated Revenue_Size for Paces), counter at 5 ***\n",
      "Debug field is  Website  for firm  Paces  and id  2945\n",
      "Getting urls of top webpages\n",
      "Getting Contents of the website of PACEsConnection with url https://www.acesconnectioninfo.com/\n",
      "Getting Contents of the website of Home [www.paces.com] with url https://www.paces.com/\n",
      "Getting Contents of the website of NBA with url https://www.nba.com/pacers/\n",
      "Getting Contents of the website of The Official Web Site for The State of New Jersey with url https://www.nj.gov/njyrs/education/paces/\n",
      "Getting Contents of the website of Paces with url https://www.pacesep.org/\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "****Successfully updated Website for Paces), counter at 6 ***\n",
      "Debug field is  NAICS_Code  for firm  Paces  and id  2945\n",
      "Getting urls of top webpages\n",
      "Getting Contents of the website of NAICS Association with url https://www.naics.com/six-digit-naics/\n",
      "Getting Contents of the website of NAICS Code Lookup - NAICS List with url https://naicslist.com/look-up\n",
      "Getting Contents of the website of Census.gov with url https://www.census.gov/naics/index.html\n",
      "Getting Contents of the website of U.S. Bureau of Labor Statistics with url https://www.bls.gov/ces/naics/home.htm\n",
      "Getting Contents of the website of NAICS List - Find Industry Classification Codes with url https://naicslist.com/lookup\n",
      "Requests Error fetching the URL https://www.bls.gov/ces/naics/home.htm: 403 Client Error: Forbidden for url: https://www.bls.gov/ces/naics/home.htm\n",
      "Requests Error fetching the URL https://naicslist.com/look-up: 403 Client Error: Forbidden for url: https://naicslist.com/look-up\n",
      "Requests Error fetching the URL https://naicslist.com/lookup: 403 Client Error: Forbidden for url: https://naicslist.com/lookup\n",
      "****Successfully updated NAICS_Code for Paces), counter at 7 ***\n",
      "Debug field is  SIC_Code  for firm  Paces  and id  2945\n",
      "Getting urls of top webpages\n",
      "Getting Contents of the website of SICCODE.com with url https://siccode.com/search-naics/pace\n",
      "Getting Contents of the website of NAICS Association with url https://www.naics.com/search/\n",
      "Getting Contents of the website of ZoomInfo with url https://www.zoominfo.com/c/paces-contracting-services-llc/1132578202\n",
      "Getting Contents of the website of SEC.gov with url https://www.sec.gov/search-filings/standard-industrial-classification-sic-code-list\n",
      "Getting Contents of the website of Occupational Safety and Health Administration with url https://www.osha.gov/ords/imis/sicsearch.html\n",
      "Requests Error fetching the URL https://www.osha.gov/ords/imis/sicsearch.html: 403 Client Error: Forbidden for url: https://www.osha.gov/ords/imis/sicsearch.html\n",
      "Requests Error fetching the URL https://www.zoominfo.com/c/paces-contracting-services-llc/1132578202: 403 Client Error: Forbidden for url: https://www.zoominfo.com/c/paces-contracting-services-llc/1132578202\n",
      "Requests Error fetching the URL https://www.sec.gov/search-filings/standard-industrial-classification-sic-code-list: 403 Client Error: Forbidden for url: https://www.sec.gov/search-filings/standard-industrial-classification-sic-code-list\n",
      "****Successfully updated SIC_Code for Paces), counter at 8 ***\n",
      "Debug field is  Status  for firm  Paces  and id  2945\n",
      "Getting urls of top webpages\n",
      "Getting Contents of the website of ePACES with url https://epaces.emedny.org/\n",
      "Getting Contents of the website of DHCS with url https://www.dhcs.ca.gov/formsandpubs/laws/hipaa/Pages/1.16-PACES.aspx\n",
      "Getting Contents of the website of eMedNY with url https://www.emedny.org/HIPAA/QuickRefDocs/ePACES-Claim_Status_Inquiry_Response.pdf\n",
      "Getting Contents of the website of USCIS with url https://egov.uscis.gov/\n",
      "Getting Contents of the website of PA.GOV with url https://www.pa.gov/agencies/aging/aging-programs-and-services/pace-program.html\n",
      "Requests Error fetching the URL https://www.dhcs.ca.gov/formsandpubs/laws/hipaa/Pages/1.16-PACES.aspx: 403 Client Error: Forbidden for url: https://www.dhcs.ca.gov/formsandpubs/laws/hipaa/Pages/1.16-PACES.aspx\n",
      "Requests Error fetching the URL https://egov.uscis.gov/: 403 Client Error: Forbidden for url: https://egov.uscis.gov/\n",
      "****Successfully updated Status for Paces), counter at 9 ***\n",
      "Debug field is  Dissolvement_Year  for firm  Paces  and id  2945\n",
      "Getting urls of top webpages\n",
      "Getting Contents of the website of Wikipedia with url https://en.wikipedia.org/wiki/Dissolution_of_Czechoslovakia\n",
      "Getting Contents of the website of Britannica with url https://www.britannica.com/event/the-collapse-of-the-Soviet-Union\n",
      "Getting Contents of the website of A Look Back and the Road Ahead for 2025 - paces.com with url https://www.paces.com/post/a-look-back-and-the-road-ahead-for-2025\n",
      "Getting Contents of the website of NPR with url https://www.npr.org/2025/01/28/nx-s1-5276293/trump-executive-orders\n",
      "Getting Contents of the website of Paces's Take: What the 2024 Election Result Means for Clean Energy with url https://www.paces.com/post/paces-take-what-the-2024-election-result-means-for-clean-energy\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "****Successfully updated Dissolvement_Year for Paces), counter at 10 ***\n",
      "Debug field is  Company_Type  for firm  Paces  and id  2945\n",
      "Getting urls of top webpages\n",
      "Getting Contents of the website of PitchBook with url https://pitchbook.com/profiles/company/491718-52\n",
      "Getting Contents of the website of paces.com - Accelerating Clean Energy Infrastructure with url https://www.paces.com/\n",
      "Getting Contents of the website of Tracxn with url https://tracxn.com/d/companies/paces/__BK2u0IRIHfz54RpUKTq1CNoEQKQUxIfPgVyHsXNXEcg\n",
      "Getting Contents of the website of OurCrowd with url https://www.ourcrowd.com/startup/paces\n",
      "Getting Contents of the website of A Look Back and the Road Ahead for 2025 - paces.com with url https://www.paces.com/post/a-look-back-and-the-road-ahead-for-2025\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "Requests Error fetching the URL https://tracxn.com/d/companies/paces/__BK2u0IRIHfz54RpUKTq1CNoEQKQUxIfPgVyHsXNXEcg: 404 Client Error: Not Found for url: https://tracxn.com/d/companies/paces/__BK2u0IRIHfz54RpUKTq1CNoEQKQUxIfPgVyHsXNXEcg\n",
      "Requests Error fetching the URL https://pitchbook.com/profiles/company/491718-52: 403 Client Error: Forbidden for url: https://pitchbook.com/profiles/company/491718-52\n",
      "****Successfully updated Company_Type for Paces), counter at 11 ***\n",
      "Debug field is  Previous_Names  for firm  Paces  and id  2945\n",
      "Getting urls of top webpages\n",
      "Getting Contents of the website of Wikipedia with url https://en.wikipedia.org/wiki/Renaming_of_cities_in_India\n",
      "Getting Contents of the website of Infoplease with url https://www.infoplease.com/geography/former-place-names-countries-and-cities\n",
      "Getting Contents of the website of GKToday with url https://www.gktoday.in/old-names-of-the-countries/\n",
      "Getting Contents of the website of 24/7 Wall St. with url https://247wallst.com/special-report/2022/07/10/17-countries-that-have-changed-their-names/\n",
      "Getting Contents of the website of Genealogy Trails with url https://genealogytrails.com/utah/state/history/history_orgofplacenames.html\n",
      "Requests Error fetching the URL https://247wallst.com/special-report/2022/07/10/17-countries-that-have-changed-their-names/: 403 Client Error: Forbidden for url: https://247wallst.com/special-report/2022/07/10/17-countries-that-have-changed-their-names/\n",
      "****Successfully updated Previous_Names for Paces), counter at 12 ***\n",
      "Debug field is  Alternative_Names  for firm  Paces  and id  2945\n",
      "Getting urls of top webpages\n",
      "Getting Contents of the website of Merriam Webster with url https://www.merriam-webster.com/thesaurus/paces\n",
      "Getting Contents of the website of WordHippo with url https://www.wordhippo.com/what-is/another-word-for/paces.html\n",
      "Getting Contents of the website of Power Thesaurus with url https://www.powerthesaurus.org/paces\n",
      "Getting Contents of the website of Free Thesaurus with url https://www.freethesaurus.com/paces\n",
      "Getting Contents of the website of YourDictionary.com with url https://thesaurus.yourdictionary.com/paces\n",
      "Requests Error fetching the URL https://www.powerthesaurus.org/paces: 403 Client Error: Forbidden for url: https://www.powerthesaurus.org/paces\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "****Successfully updated Alternative_Names for Paces), counter at 13 ***\n",
      "Debug field is  Key_Executive_Personnel  for firm  Paces  and id  2945\n",
      "Getting urls of top webpages\n",
      "Getting Contents of the website of Craft with url https://craft.co/pace-groups/executives\n",
      "Getting Contents of the website of Leadership - Paces with url https://www.pacescenter.org/leadership\n",
      "Getting Contents of the website of Governance - Paces with url https://www.pacesep.org/about-paces/governance/\n",
      "Getting Contents of the website of A Look Back and the Road Ahead for 2025 - paces.com with url https://www.paces.com/post/a-look-back-and-the-road-ahead-for-2025\n",
      "Getting Contents of the website of Cause IQ with url https://www.causeiq.com/organizations/paces,271701100/\n",
      "Requests Error fetching the URL https://craft.co/pace-groups/executives: 403 Client Error: Forbidden for url: https://craft.co/pace-groups/executives\n",
      "An error occurred with Selenium:: Page load exceeded time limit of 5 secondsAn error occurred with Selenium:: Page load exceeded time limit of 5 seconds\n",
      "\n",
      "****Successfully updated Key_Executive_Personnel for Paces), counter at 14 ***\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "counter = 0\n",
    "\n",
    "for i,row in df.iterrows():\n",
    "    row = row.to_dict()\n",
    "    firm_id = row['id']\n",
    "    firm_name = row['name']\n",
    "    print(\"----- Debug: Now on firm: \", firm_name, \" -----\", firm_id)\n",
    "\n",
    "    # Check if a row for the firm already exists in the target database, insert row if it doesnt\n",
    "    cursor_websites.execute(\"SELECT id FROM firms_web_search_website_scrapings WHERE id = ? AND Firm_Name = ?\", (firm_id, firm_name,))\n",
    "    firm_row = cursor_websites.fetchone()\n",
    "    if firm_row is None:\n",
    "        print(\"Inserting new firm:, \", firm_name)\n",
    "        cursor_websites.execute(\"INSERT INTO firms_web_search_website_scrapings (id, Firm_Name) VALUES (?,?)\", (firm_id,firm_name,))\n",
    "        firm_id = cursor_websites.lastrowid  \n",
    "    else:\n",
    "        # print(\"Found row for firm, \", firm_name)\n",
    "        firm_id = firm_row[0]\n",
    "\n",
    "    # Now iterate through each field's search results for the given firm\n",
    "    for field in fields:\n",
    "        print(\"Debug field is \", field, \" for firm \", firm_name , \" and id \", firm_id)\n",
    "\n",
    "        # Check if the field value in the target database is NULL to decide if we need to fill it in\n",
    "        cursor_websites.execute(f\"SELECT {field} FROM firms_web_search_website_scrapings WHERE id = ? AND Firm_Name = ? AND {field} IS NOT NULL\", (firm_id,firm_name,))\n",
    "        existing_result = cursor_websites.fetchone()\n",
    "        # If the field already has a value, skip this iteration\n",
    "        if existing_result is not None and existing_result[0] != '{}':\n",
    "            print(f\"Field '{field}' already has data for firm '{firm_name}', skipping.\")\n",
    "            continue\n",
    "      \n",
    "        #get the websearch results\n",
    "        cursor_websearch.execute(f\"SELECT {field} FROM firms_web_search_results WHERE id = ? AND Firm_Name = ?\", (firm_id, firm_name,))\n",
    "        web_search_result = cursor_websearch.fetchone()\n",
    "\n",
    "        # check that bing web search results are actually available\n",
    "        if (web_search_result is not None) and (web_search_result[0] is not None):\n",
    "            web_search_result = json.loads(web_search_result[0])\n",
    "        else:\n",
    "            web_search_result = \"No web search data available\" # skip the iteration, nothing to do\n",
    "            continue\n",
    "\n",
    "        # Get the website URLs from the web search results\n",
    "        try:\n",
    "            # print(\"web_search_result is \", web_search_result)\n",
    "            # skip failed search\n",
    "            if web_search_result == \"Bing Search has failed\" or web_search_result is None:\n",
    "                print(\" Skipping failed search, for field \", field)\n",
    "                continue\n",
    "\n",
    "            # Get the top 5 webpages from the search results\n",
    "            webpages = site_scraper.get_top_webpages(web_search_result)\n",
    "            website_info = {} # initialize dictionary to fill\n",
    "\n",
    "            # Use paralllism to scrape the 5 websites simultaneous with 5 Selenium instances\n",
    "\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "                # Submit each website scrape task to the executor with a unique SiteScraper instance\n",
    "                future_to_site = {\n",
    "                    executor.submit(scrape_website, scrapers[i % 5], name, url): name\n",
    "                    for i, (name, url) in enumerate(webpages.items())\n",
    "                }\n",
    "\n",
    "                # Collect results as they complete\n",
    "                for future in concurrent.futures.as_completed(future_to_site):\n",
    "                    website_name = future_to_site[future]\n",
    "                    try:\n",
    "                        name, result = future.result()\n",
    "                        website_info[name] = result\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error scraping {website_name}: {e}\")\n",
    "\n",
    "            website_info = json.dumps(website_info)\n",
    "\n",
    "            # Update cell value in database\n",
    "            cursor_websites.execute(f\"\"\"\n",
    "                        UPDATE firms_web_search_website_scrapings\n",
    "                        SET {field} = ?\n",
    "                        WHERE id = ? AND Firm_Name = ?\n",
    "                        \"\"\", (website_info, firm_id, firm_name))\n",
    "            \n",
    "            conn_websites.commit()\n",
    "            counter += 1\n",
    "            print(f\"****Successfully updated {field} for {firm_name}), counter at {counter} ***\")\n",
    "\n",
    "        except SeleniumExtractionError as e:\n",
    "            print(f\"Error extracting data for {firm_name} and {field}: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Paces']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = df.name.tolist()\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Display some results for Demo purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cursor_websites.execute(\"SELECT * FROM firms_web_search_website_scrapings WHERE Firm_Name IN ({})\".format(\n",
    "    \",\".join([\"?\"] * len(df))\n",
    "), names).fetchall()\n",
    "data_dict = json.loads(data[0][2]) # registered address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SGPBusiness.com': 'Just a moment... www.sgpbusiness.com Verifying you are human. This may take a few seconds. www.sgpbusiness.com needs to review the security of your connection before proceeding. Verification successful Waiting for www.sgpbusiness.com to respond... Enable JavaScript and cookies to continue Ray ID: 90d4f1ce3971e1ce Performance & security by Cloudflare',\n",
       " \"PACES OFFICES – Palestine Association for Children's Encouragement of ...\": \" PACES OFFICES – Palestine Association for Children's Encouragement of Sports – PACES العربية English Arabic Facebook Profile Twitter Profile Youtube Profile LinkedIn Profile Instagram Profile DONATE HOME WHO WE ARE About Us IMPACT MODEL LEADERSHIP Partners & Donors SUPPORT US Annual Reports WORK WITH US WHAT WE DO Program Beneficiaries ACTIVITIES Gaza Relief Program Campaigns Past Campaigns PACES Child Protection Policy WHERE WE WORK Countries PACES OFFICES RESOURCES MEDIA NEWS CONTACT SEARCH Search for: Search PACES OFFICES PALESTINE HEAD OFFICE – Ramallah/Al Bireh AL Fara’ Building, Baghdad Street Tel: +972 22421771 Jerusalem 5 Nablus Road, YMCA Building, East Tel: +972 226275860/1 JORDAN 75 Zahran Street Jabal Amman Amman Tel: +962 6 4647541 LEBANON 4th Floor, Block B, Antwork May Ziadeh Street Spears, Beirut United Kingdom REGISTERED OFFICE Carter Lemon Camerons LLP 3 rd Floor, 20 King Street London EC2V 8EG Join Our Mailing List Stay updated with our latest news Leave this field empty if you're human: Contact Info Head Office Phone: +972 22421771 Email: [email protected] Address: Ramallah/Al Bireh AL Fara’ Building, Baghdad Street REGISTRATION PACES is a UK Registered Charity Number 1117085 Privacy Policy English العربية ( Arabic ) © Copyright 2025 PACES Charity \",\n",
       " 'Live Active': ' PACES | Sports Development Skip navigation Breadalbane Community Campus : Our current opening hours have been adjusted from the usual schedule. Tap here for more details. Activities Our Venues Perth City Venues Perth Leisure Pool Dewars Centre North Inch Community Campus George Duncan Athletics Arena Glenearn Community Campus Kinross Venues Live Active Loch Leven Loch Leven Community Campus Live Active Strathearn Live Active Blairgowrie Highland Venues Live Active Atholl Breadalbane Community Campus At Home Hub Community Halls Timetables Membership & Pricing Memberships Fitness Memberships Student Membership Atholl Fitness Membership Active Fun Membership (5-11yrs) Active Energy Membership (12-15yrs) Membership Queries Pay As You Go Live Active Rewards Concessions Information I Want To Join Now Direct Debit Membership 30 Day Membership Annual Membership Live Active Card Only Book Online Work with us Recruitment Training and Development UK Coaching Courses Volunteering opportunities Corporate Reward Your Employees Advertising & Sponsorship Events & Conferences Join Live Active Rewards Live Active Tourist Corporate Curling Packages Activities Our Venues Our Venues Perth City Venues Perth City Venues Perth Leisure Pool Dewars Centre North Inch Community Campus George Duncan Athletics Arena Glenearn Community Campus Kinross Venues Kinross Venues Live Active Loch Leven Loch Leven Community Campus Live Active Strathearn Live Active Blairgowrie Highland Venues Highland Venues Live Active Atholl Breadalbane Community Campus At Home Hub Community Halls Timetables Membership & Pricing Membership & Pricing Memberships Memberships Fitness Memberships Student Membership Atholl Fitness Membership Active Fun Membership (5-11yrs) Active Energy Membership (12-15yrs) Membership Queries Pay As You Go Live Active Rewards Concessions Information I Want To Join Now I Want To Join Now Direct Debit Membership 30 Day Membership Annual Membership Live Active Card Only Book Online Work with us Work with us Recruitment Training and Development UK Coaching Courses Volunteering opportunities Corporate Corporate Reward Your Employees Advertising & Sponsorship Events & Conferences Join Live Active Rewards Live Active Tourist Corporate Curling Packages Book now Home PACES & Accredited Clubs Clubs & Sport Development PACES & Accredited Clubs The Perth and Kinross Accredited Club Excellence Scheme (PACES), is a straightforward quality assurance system that has been designed to help sports clubs operate efficiently and effectively. It will help your club to take a systematic look at what it does, and decide exactly where improvements can be made. It is also a means of identifying and rewarding clubs that operate in a structured way. We have three levels for PACES membership: Bronze, Silver & Gold. Each level supports a progression within club activity and structure. Benefits of PACES Support and advice from the Live Active Sport Development Team Access to lets within Live Active Leisure and Perth and Kinross Council facilities (e.g. PACES is required for booking a hall / court) Eligibility to apply for funding from Live Active Sport and Perth & Kinross Sports Council Opportunity to work with Active Schools Co-ordinators to support school to club links Promotion through our online media and campaigns such as the Perth and Kinross Sports Awards Free places on Child Protection and Wellbeing and First Aid courses The benefits and support your club will recieve will depend on what level of PACES your club has been accredited with; Bronze, Silver or Gold. To find out more about PACES, to register or renew your club please visit www.paces.org.uk Find a PACES Club The map below shows where PACES sports clubs are based across Perth and Kinross. The clubs on the map have achieved either bronze, silver or gold level. If your club is not on the map and you would like to join PACES, please visit www.paces.org.uk . Read More About News Blog About Us Our Partners Support Us FAQs Staff Portal Key Info Privacy Cookies T&Cs Small print Publications of Information Contact Us Contact Feedback [email protected] Registered Office: Dewars Centre, Glover Street, Perth, PH2 0TH. Registered in Scotland No SC042641 VAT Registration No: 1254634 26 A Company Limited by Guarantee and a Registered Charity No. SC000175. < THANKS TO OUR PARTNERS © Copyright 2025, Live Active Lesiure Website by mtc. We use first and third-party cookies to give you the best possible experience on our website and for personalised advertising & social media monitoring. Accept More Info',\n",
       " 'OpenCorporates': ' Entity Details :: OpenCorporates NOTICE: The OpenCorporates web portal will be down for planned maintenance on Mondays the 17th of February, the 24th of February, and the 3rd of March, from 06:45 to 15:00 GMT. We apologise for any inconvenience. The Open Database Of The Corporate World Search Companies Officers Log in/Sign up PACES FUNDING, LLC Company Number 09069077 Previous Company Numbers 1599143 Status Active/Owes Current Year Ar Incorporation Date Please log in to see this data Company Type Domestic Limited Liability Company Jurisdiction Georgia (US) Registered Address 3015 B Piedmont Rd Atlanta 30305 GA United States Agent Name Bryan M Knight Agent Address 1360 Peachtree St., Suite 1201, Atlanta, GA, 30309, United States Directors / Officers 1 officer available, please log in to see this data Recent filings for PACES FUNDING, LLC 22 May 2024 Amended Annual Registration Domestic Limited Liability Company 5 Feb 2024 Annual Registration Domestic Limited Liability Company 3 Feb 2023 Annual Registration Domestic Limited Liability Company 19 Oct 2022 Amended Annual Registration Domestic Limited Liability Company 7 Feb 2022 Annual Registration Domestic Limited Liability Company 24 May 2021 Certificate Of Existence Domestic Limited Liability Company 11 Jan 2021 Annual Registration Domestic Limited Liability Company 11 Feb 2020 Amended Annual Registration Domestic Limited Liability Company see all filings Data source and freshness Last update from source Last change recorded Next update from source Source Please log in to see this data Learn more about our trust and data transparency policy This information comes to you from OpenCorporates — the leading authority on legal-entity data Read more about us and why you should trust this data in our purpose, history and principles The OpenCorporates website is free for general-public and public-benefit use Use the OpenCorporates API License this data in bulk Similarly named companies Paces Funding Holding, LLC (Georgia (US)) * While we strive to keep this information correct and up-to-date, it is not the primary source, and the company registry should always be referred to for definitive information OpenCorporates : legal-entity data done right Global Authority Unrivalled domain expertise Driving global policy Certified B Corp Trustworthy data 100% official primary sources Quality baked in Underpinned by Legal-Entity Data Principles Designed for the future Legal-entity data model For the needs of today and tomorrow Provenanced, standardized data Learn more About us About Blog Team Governance Jobs Using our data Our data Our purpose Legal/Licence User/Cookie privacy policy Public records privacy policy Help API Reference Glossary Status Contact Twitter Medium Newsletter Problems with our data? Temporary redaction Impact Impact Grants',\n",
       " 'The Official Web Site for The State of New Jersey': \" PACES Skip to Content Healthy New Jersey Official Site of The State of New Jersey Governor Phil Murphy • Lt. Governor Tahesha Way NJ.gov Services Agencies FAQs Frequently Asked Questions Translate The State of NJ site may contain optional links, information, services and/or content from other websites operated by third parties that are provided as a convenience, such as Googleâ\\x84¢ Translate. Googleâ\\x84¢ Translate is an online service for which the user pays nothing to obtain a purported language translation. The user is on notice that neither the State of NJ site nor its operators review any of the services, information and/or content from anything that may be linked to the State of NJ site for any reason. - Read Full Disclaimer close Get Updates close Search close New Jersey Youth Resource Spot Toggle Social Links Open/Close Twitter Facebook Instagram LinkedIn New Jersey Youth Resource Spot Home DCF Connected Services & Resources Services & Resources Overview EnlightenMENT Wraparound Funds LifeSet One Simple Wish Lifeskills Programs PACES Education Education Overview High School IEP Financial Aid Scholarships College Success PACES Skilled Trade Housing Housing Overview Adolescent Housing Hub Apartment Leasing Gap Housing Health Health Overview Insurance Physical Health Sexual Health Mental Health Self Care Physical and Mental Health Apps Expectant and Parenting Youth Youth Living with HIV/AIDS Life Skills Life Skills Overview Life Skills Programs Important Documents Financial Literacy Transportation Voting Identity Theft and Online Safety Employment Employment Overview Career Exploration Resume/Cover Letter Finding a Job The Interview Process Trade Careers LGBTQI+ Legal Legal Overview Your Legal Rights Rights of Siblings Rights of Adoptees Attending Court Requesting a Copy of Your File Knowing Your Law Guardian Disability and Social Security Benefits Court Appointed Special Advocate (CASA) Immigration Resources Get Involved Get Involved Overview Statewide National Things to Remember when Getting Involved National Youth in Transition Database (NYTD) Survey About NJYRS Education Home Education PACES PACES Pathways to Academic and Career Exploration to Success (PACES) The Pathways to Academic and Career Exploration to Success (PACES) program supports current or former foster youth and young adults in their successful transition to and retention in post-secondary education (including career technical education) and workforce readiness.â\\x80¯ The target population for these programs will be youth and young adults ages 16-21 who are eligible for NJ Foster Care (NJFC) Scholars as determined by DCF.â\\x80¯ For details about eligibility please click here . The PACES programs' academic and career coaches will address identified academic needs, typically in reading, writing, and/or math; assist students in career exploration to promote college and career readiness; help students prepare for, identify, and apply to career technical schools or colleges and universities that are a best fit; and prepare students for their adjustment to and integration into their post-secondary communities. The PACES providers will serve youth who live within the Region they cover.â\\x80¯ The following is a list of PACES provider agencies with the counties served. Atlantic, Burlington, Camden, Cape May, Cumberland, Gloucester, and Salem Acenda Telephone Number: 844-422-3632 Address: 41 S. Delsea Drive, Glassboro, NJ 08028 Email : pacesreferrals@acendahealth.org Bergen, Hudson, Morris, Passaic, Sussex, and Warren Care Plus Telephone Number: 201-265-8200 Address: 17-07 Romaine Street, Fair Lawn, NJ 07410 Email : PACESreferrals@careplusnj.org Essex and Union Community Access Unlimited Telephone Number: 908-354-3040 Address: 80 W Grand St, Elizabeth NJ 07202 Email : info@caunj.org Hunterdon, Mercer, Middlesex, Monmouth, Ocean, and Somerset Embrella Telephone Number: 609-520-1500 Address: 101 College Rd E 3rd Floor, Princeton NJ 08540 Email : paces@embrella.org For more detailed information about the program including the referral process you may also contact Emel Altomari from the Office of Family Preservation and Reunification by phone at 609 888-7592 or email at emel.altomari@dcf.nj.gov Share this webpage with one click Twitter Facebook Instagram LinkedIn E-Mail The NJ Youth Resource Spot (NJYRS) is a website created for young people, by young people. The majority of the content, images, and format you see today was written and selected by the New Jersey Department of Children and Families (NJ DCF) Youth Council members who have lived experience with the Division of Child Protection and Permanency (DCP&P), the Childrenâ\\x80\\x99s System of Care (CSOC) and the DCF Regional Schools. Members work passionately to provide youth like you the most helpful and accurate information available. New Jersey Youth Resource Spot Home DCF Connected Services & Resources Services & Resources Overview EnlightenMENT Wraparound Funds LifeSet One Simple Wish Lifeskills Programs PACES Education Education Overview High School IEP Financial Aid Scholarships College Success PACES Skilled Trade Housing Housing Overview Adolescent Housing Hub Apartment Leasing Gap Housing Health Health Overview Insurance Physical Health Sexual Health Mental Health Self Care Physical and Mental Health Apps Expectant and Parenting Youth Youth Living with HIV/AIDS Life Skills Life Skills Overview Life Skills Programs Important Documents Financial Literacy Transportation Voting Identity Theft and Online Safety Employment Employment Overview Career Exploration Resume/Cover Letter Finding a Job The Interview Process Trade Careers LGBTQI+ Legal Legal Overview Your Legal Rights Rights of Siblings Rights of Adoptees Attending Court Requesting a Copy of Your File Knowing Your Law Guardian Disability and Social Security Benefits Court Appointed Special Advocate (CASA) Immigration Resources Get Involved Get Involved Overview Statewide National Things to Remember when Getting Involved National Youth in Transition Database (NYTD) Survey About NJYRS Statewide Governor Phil Murphy Lt. Governor Tahesha Way NJ Home Services A to Z Departments/Agencies FAQs Frequently Asked Questions Contact Us Privacy Notice Legal Statement & Disclaimers Accessibility Statement Twitter Facebook Instagram LinkedIn Copyright © State of New Jersey, 1996- Department of Children and Families P.O. Box 729 Trenton, NJ 08625-0729 × example Modal Label Close Ã\\x97 We want to know more about our users. How would you describe yourself? Youth Caregiver/Guardian Professional Back to top\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # close all cursosrs and connections\n",
    "cursor_websearch.close()\n",
    "cursor_websites.close()\n",
    "conn_websearch.close()\n",
    "conn_websites.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze lengths of results to determine a suitable token cutoff point (save on costs during trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the results\n",
    "data = []\n",
    "lengths = []\n",
    "\n",
    "# Get all firms from the database\n",
    "cursor_websites.execute('SELECT id, Firm_Name FROM firms_web_search_website_scrapings WHERE id > 2000')\n",
    "firm_records = cursor_websites.fetchall()\n",
    "\n",
    "for firm_record in firm_records:\n",
    "    firm_id = firm_record[0]\n",
    "    firm_name = firm_record[1]\n",
    "    firm_data = {'id': firm_id, 'Firm_Name': firm_name}\n",
    "    \n",
    "    print(f\"Processing firm: {firm_name} (ID: {firm_id})\")\n",
    "    \n",
    "    for field in fields:\n",
    "        # Fetch the content of the field\n",
    "        cursor_websites.execute(f'''\n",
    "            SELECT {field} FROM firms_web_search_website_scrapings\n",
    "            WHERE id = ? AND Firm_Name = ?\n",
    "        ''', (firm_id, firm_name))\n",
    "        \n",
    "        result = cursor_websites.fetchone()\n",
    "        if result:\n",
    "            content = result[0]\n",
    "            if content:\n",
    "                try:\n",
    "                    # Parse the JSON content if necessary\n",
    "                    content_json = json.loads(content)\n",
    "                    # Flatten the JSON to a string\n",
    "                    content_str = json.dumps(content_json)\n",
    "                    content_length = len(content_str)\n",
    "                except json.JSONDecodeError:\n",
    "                    # If content is not JSON, treat it as a string\n",
    "                    content_length = len(content)\n",
    "            else:\n",
    "                content_length = 0\n",
    "        else:\n",
    "            content_length = 0\n",
    "        \n",
    "        # Add the length to the firm_data dictionary\n",
    "        firm_data[field] = content_length\n",
    "        lengths.append(content_length)\n",
    "    \n",
    "    # Append the firm_data to the data list\n",
    "    data.append(firm_data)\n",
    "\n",
    "# Convert the data list to a pandas DataFrame\n",
    "df_lengths = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lengths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_series = pd.Series(lengths)\n",
    "\n",
    "percentiles = [50, 75, 90, 91,92,93,94, 95, 96, 97, 98, 99]\n",
    "\n",
    "combined_percentiles = lengths_series.quantile([p / 100 for p in percentiles])\n",
    "\n",
    "print(f\"\\nPercentiles across all fields:\")\n",
    "print(combined_percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_series[lengths_series < 1000000].mean()/ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = lengths_series[lengths_series < 976996.73 ]\n",
    "int(v.sum() / 4) /1000000 * 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_websearch.close()\n",
    "conn_websearch.close()\n",
    "cursor_websites.close()\n",
    "conn_websites.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equifax_practicum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
